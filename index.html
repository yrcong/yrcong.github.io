<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Academic Homepage</title>
  <meta name="description" content="Personal academic webpage." />
  <style>
    /*==== Fancy technical theme ====*/
    @import url('https://fonts.googleapis.com/css2?family=Optimistic+Text:wght@400;600&display=swap');
    :root{
      --text:#0f172a; --muted:#64748b; --line:#e2e8f0; --accent:#2563eb; --accent-2:#22d3ee;
      --bg:#ffffff; --panel:#f8fafc; --radius:12px; --sidebar:260px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      --optimistic: 'Optimistic Text', sans-serif;
    }
    [data-theme="dark"]{
      --text:#e5e7eb; --muted:#94a3b8; --line:#1f2937; --accent:#60a5fa; --accent-2:#22d3ee;
      --bg:#0b1220; --panel:#0f172a;
    }

    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0; font-family: var(--optimistic), system-ui, sans-serif;
      color:var(--text); background:var(--bg); line-height:1.65;
      background-image:
        radial-gradient(circle at 20% -10%, color-mix(in srgb, var(--accent) 12%, transparent) 0, transparent 60%),
        radial-gradient(circle at 120% 0%, color-mix(in srgb, var(--accent-2) 12%, transparent) 0, transparent 60%),
        linear-gradient(0deg, transparent 24px, color-mix(in srgb, var(--line) 40%, transparent) 25px),
        linear-gradient(90deg, transparent 24px, color-mix(in srgb, var(--line) 40%, transparent) 25px);
      background-size: 100% 100%, 100% 100%, 25px 25px, 25px 25px;
      background-attachment: fixed;
    }

    a{color:var(--accent); text-decoration:none}
    a:hover{text-decoration:underline}
    a[href^="http"]::after{content:"↗"; font-family: var(--mono); font-size:.8em; margin-left:.25em; opacity:.7}

    .wrap{max-width:1100px; margin:0 auto; padding:24px}
    .layout{display:grid; grid-template-columns: var(--sidebar) 1fr; gap:28px}
    @media (max-width: 820px){ .layout{grid-template-columns: 1fr} }

    /* Sidebar */
    .side{position:sticky; top:20px; align-self:start; border:1px solid var(--line); border-radius:var(--radius); padding:16px; background:var(--panel); box-shadow: 0 8px 30px rgba(2,6,23,.12)}
    .name{font-size:22px; margin:10px 0 4px}
    .roles{color:var(--muted); font-size:14px; margin:0}
    .photo{width:100%; aspect-ratio:1/1; border-radius:10px; object-fit:cover; border:1px solid var(--line); background:#fff}
    .links{display:flex; flex-direction:column; gap:6px; margin-top:12px; font-size:14px}

    /* Content */
    main{min-width:0}
    section{padding:20px 0; border-bottom:1px dashed var(--line)}
    section:last-of-type{border-bottom:none}

    h2{font-size:20px; margin:0 0 10px; font-family: var(--mono); letter-spacing:.2px; display:flex; align-items:center; gap:.5rem}

    .lead{margin:4px 0 8px; color:var(--muted)}
    .meta{color:var(--muted); font-size:14px}
    ul.simple, ul.pubs{margin:0; padding-left:18px}

    /* Photos grid */
    .gallery{display:grid; grid-template-columns: repeat(3, 1fr); gap:10px}
    .gallery img{width:100%; height:180px; border:1px solid var(--line); border-radius:10px; object-fit:cover}
    @media (max-width:920px){ .gallery{grid-template-columns: 1fr 1fr} }

    /* Top tabs + theme toggle */
    header{border-bottom:1px solid var(--line); position:sticky; top:0; background:color-mix(in srgb, var(--bg) 92%, transparent); backdrop-filter: saturate(1.2) blur(6px); z-index:10}
    .tabs{display:flex; gap:14px; align-items:center; max-width:1100px; margin:0 auto; padding:10px 24px}
    .tabs a{font-size:13px; color:var(--text); font-family:var(--mono)}
    .spacer{flex:1}
    .toggle{border:1px solid var(--line); background:var(--panel); color:var(--text); border-radius:999px; font-family:var(--mono); font-size:12px; padding:6px 10px}
    .toggle:hover{border-color: color-mix(in srgb, var(--accent) 40%, transparent)}

    .rule{height:1px; background: linear-gradient(90deg, transparent, color-mix(in srgb, var(--accent) 40%, transparent), transparent); border:none}
    /* Publication media list */
    .pubs{list-style:none; padding-left:0; display:flex; flex-direction:column; gap:14px}
    .pub-item{display:grid; grid-template-columns:240px 1fr; gap:14px; align-items:start; border:1px solid var(--line); border-radius:10px; padding:10px; background:var(--panel)}
    .pub-thumb{
      width:240px;
      aspect-ratio: 3 / 2;
      object-fit: contain;
      background:#fff;
    }
    .pub-meta{font-size:14px; color:var(--muted)}
    .pub-links{margin-top:6px}
    .pub-links a{margin-right:10px}
    @media (max-width:640px){ .pub-item{grid-template-columns:1fr} .pub-thumb{width:100%; height:160px} }
  </style>
</head>
<body>
  <header>
    <nav class="tabs" aria-label="Primary">
      <a href="#about">About</a>
      <a href="#news">News</a>
      <a href="#publications">Publications</a>
      <!-- <a href="#talks">Talks</a> -->
      <a href="#contact">Contact</a>
      <span class="spacer"></span>
      <button id="theme-toggle" class="toggle" type="button">dark</button>
    </nav>
  </header>

  <div class="wrap">
    <div class="layout">
      <aside class="side">
        <img class="photo" alt="Profile photo of Your Name" src="images/profile.jpg" />
        <h1 class="name" id="site-title">Yuren Cong (丛裕人)</h1>
        <p class="roles">AI Research Scientist, Meta<br/>congyuren[at]hotmail.com</p>
        <div class="links" aria-label="Profiles">
          <a href="https://scholar.google.co.uk/citations?user=6DPcOUEAAAAJ&hl=en&oi=ao">Google Scholar</a>
          <a href="https://github.com/yrcong">GitHub</a>
          <a href="https://www.linkedin.com/in/yuren-cong-78626a193/">LinkedIn</a>
          <a href="https://x.com/CongYuren">Twitter</a>
        </div>
      </aside>

      <main id="main">
        <section id="about">
          <h2>About</h2>
          <p class="lead">Research Scientist, Meta AI</p>
          <p>
            <b>Hello</b>! I am a research scientist at Meta, building multi-modal understanding and generation models.
          </p>
          <p>
            Previously I was a senior ML scientist at <a href="https://picsart.com/">Picsart</a>. I received my Ph.D. in Computer Science from Leibniz Hanover University, advised by <a href="https://sites.google.com/site/michaelyingyang">Prof. Michael Yang</a> and <a href="https://www.tnt.uni-hannover.de/en/staff/rosenhahn/">Prof. Bodo Rosenhahn</a>.
          </p>
        </section>

        <section id="news">
          <h2>News</h2>
          <ul class="simple">
            <li><span class="meta">Nov 2025:</span> We release <a href="https://tuna-ai.org/">TUNA</a>, A multimodal understanding and generation model!</li>
            <li><span class="meta">Jun 2025:</span> Our GenAI solution for Ads is highlighted at <a href="https://www.facebook.com/business/news/cannes-lions-2025-introducing-the-next-era-of-generative-ai-for-advertisers-and-agencies-personalization-at-scale">Cannes Lions 2025</a>.</li>
            <li><span class="meta">Mar 2025:</span> Paper on compositional image generation accepted to IJCV.</li>
            <li><span class="meta">Feb 2025:</span> Paper on virtual try-on accepted to CVPR.</li>
          </ul>
        </section>

        <section id="publications">
          <h2>Selected Publications <span class="meta"></span></h2>
          <!-- <p class="meta">(*) denotes equal contribution</p> -->

          <h3>Generative Models</h3>
          <ul class="pubs">
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/tuna.gif"/>
              <div>
                <strong>TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models</strong>
                <div class="pub-meta">Zhiheng Liu, Weiming Ren, Haozhe Liu, Zijian Zhou, Shoufa Chen, Haonan Qiu, Xiaoke Huang, Zhaochong An, Fanny Yang, Aditya Patel, Viktar Atliha, Tony Ng, Xiao Han, Chuyan Zhu, Chenyang Zhang, Ding Liu, Juan-Manuel Perez-Rua, Sen He, Jürgen Schmidhuber, Wenhu Chen, Ping Luo, Wei Liu, Tao Xiang, Jonas Schult, Yuren Cong. <em>Preprint</em>, 2025.</div>
                <div class="pub-links"><a href="https://tuna-ai.org/">Page</a> <a href="https://arxiv.org/abs/2512.02014">Paper</a> </div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/mos.jpg"/>
              <div>
                <strong>Mixture of States: Routing Token-Level Dynamics for Multimodal Generation</strong>
                <div class="pub-meta">Haozhe Liu, Ding Liu, Mingchen Zhuge, Zijian Zhou, Tian Xie, Sen He, Yukang Yang, Shuming Liu, Yuren Cong, Jiadong Guo, Hongyu Xu, Ke Xu, Kam-Woh Ng, Juan C. Pérez, Juan-ManuelPérez-Rúa, Tao Xiang, Wei Liu, Shikun Liu, Jürgen Schmidhuber. <em>Preprint</em>, 2025.</div>
                <div class="pub-links"><a href="https://arxiv.org/pdf/2511.12207">Paper</a> </div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/saber.gif"/>
              <div>
                <strong>Scaling Zero-Shot Reference-to-Video Generation</strong>
                <div class="pub-meta">Zijian Zhou, Shikun Liu, Haozhe Liu, Haonan Qiu, Zhaochong An, Weiming Ren, Zhiheng Liu, Xiaoke Huang, Kam Woh Ng, Tian Xie, Xiao Han, Yuren Cong, Hang Li, Chuyan Zhu, Aditya Patel, Tao Xiang, Sen He. <em>Preprint</em>, 2025.</div>
                <div class="pub-links"><a href="https://franciszzj.github.io/Saber/">Page</a> <a href="https://arxiv.org/pdf/2512.06905">Paper</a> </div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/actig.jpg"/>
              <div>
                <strong>Attribute-Centric Compositional Text-to-Image Generation</strong>
                <div class="pub-meta">Yuren Cong, Martin Renqiang Min, Li Erran Li, Bodo Rosenhahn, Michael Ying Yang. <em>IJCV</em>, 2025.</div>
                <div class="pub-links"><a href="https://link.springer.com/article/10.1007/s11263-025-02371-0">Paper</a> </div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/leffa.png"/>
              <div>
                <strong>Learning Flow Fields in Attention for Controllable Person Image Generation</strong>
                <div class="pub-meta">Zijian Zhou, Shikun Liu, Xiao Han, Haozhe Liu, Kam Woh Ng, Tian Xie, Yuren Cong, Hang Li, Mengmeng Xu, Juan-Manuel Perez-Rua, Aditya Patel, Tao Xiang, Miaojing Shi, Sen He. <em>CVPR</em>, 2025.</div>
                <div class="pub-links"><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Learning_Flow_Fields_in_Attention_for_Controllable_Person_Image_Generation_CVPR_2025_paper.pdf">Paper</a> <a href="https://huggingface.co/spaces/franciszzj/Leffa">Huggingface</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/flatten.gif"/>
              <div>
                <strong>FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing</strong>
                <div class="pub-meta">Yuren Cong, Mengmeng Xu, Christian Simon, Shoufa Chen, Jiawei Ren, Yanping Xie, Juan-Manuel Perez-Rua, Bodo Rosenhahn, Tao Xiang, Sen He. <em>ICLR</em>, 2024.</div>
                <div class="pub-links"><a href="https://openreview.net/pdf?id=JgqftqZQZ7">Paper</a> <a href="https://flatten-video-editing.github.io/">Page</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/gentron.gif"/>
              <div>
                <strong>GenTron: Delving Deep into Diffusion Transformers for Image and Video Generation</strong>
                <div class="pub-meta">Shoufa Chen, Mengmeng Xu, Jiawei Ren, Yuren Cong, Sen He, Yanping Xie, Animesh Sinha, Ping Luo, Tao Xiang, Juan-Manuel Perez-Rua. <em>CVPR</em> , 2024.</div>
                <div class="pub-links"><a href="https://arxiv.org/pdf/2312.04557">Paper</a> <a href="https://www.shoufachen.com/gentron_website/">Page</a></div>
              </div>
            </li>
          </ul>

          <h3>Scene Understanding</h3>
          <ul class="pubs">
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/span.png" />
              <div>
                <strong>SPAN: Learning Similarity between Scene Graphs and Images with Transformers</strong>
                <div class="pub-meta">Yuren Cong, Wentong Liao, Bodo Rosenhahn, Michael Ying Yang. <em>PAMI  </em>, 2025.</div>
                <div class="pub-links"><a href="https://arxiv.org/pdf/2304.00590">Paper</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/reltr.jpg" />
              <div>
                <strong>Reltr: Relation Transformer for Scene Graph Generation</strong>
                <div class="pub-meta">Yuren Cong, Wentong Liao, Bodo Rosenhahn, Michael Ying Yang. <em>PAMI  </em>, 2023.</div>
                <div class="pub-links"><a href="https://ieeexplore.ieee.org/abstract/document/10105507">Paper</a> <a href="https://github.com/yrcong/RelTR">Code</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/sttran.jpg" />
              <div>
                <strong>Spatial-temporal Transformer for Dynamic Scene Graph Generation</strong>
                <div class="pub-meta">Yuren Cong, Wentong Liao, Hanno Ackermann, Bodo Rosenhahn, Michael Ying Yang. <em>ICCV  </em>, 2021.</div>
                <div class="pub-links"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cong_Spatial-Temporal_Transformer_for_Dynamic_Scene_Graph_Generation_ICCV_2021_paper.pdf">Paper</a> <a href="https://github.com/yrcong/STTran">Code</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/nodis.jpg" />
              <div>
                <strong>NODIS: Neural Ordinary Differential Scene Understanding</strong>
                <div class="pub-meta">Yuren Cong, Hanno Ackermann, Wentong Liao, Michael Ying Yang, Bodo Rosenhahn. <em>ECCV  </em>, 2020.</div>
                <div class="pub-links"><a href="https://arxiv.org/pdf/2001.04735">Paper</a> <a href="https://github.com/yrcong/nodis">Code</a></div>
              </div>
            </li>
          </ul>

          <h3>Embodied AI</h3>
          <ul class="pubs">
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/isu.png" />
              <div>
                <strong>Indoor Scene Change Understanding (SCU): Segment, Describe, and Revert Any Change</strong>
                <div class="pub-meta">Mariia Khan, Yue Qiu, Yuren Cong, Bodo Rosenhahn, David Suter, Jumana Abu-Khalaf. <em>IROS  </em>, 2024.</div>
                <div class="pub-links"><a href="https://ieeexplore.ieee.org/abstract/document/10801354">Paper</a></div>
              </div>
            </li>
            <li class="pub-item">
              <img class="pub-thumb" src="images/pubs/world.png" />
              <div>
                <strong>Worldafford: Affordance Grounding Based on Natural Language Instructions</strong>
                <div class="pub-meta">Changmao Chen, Yuren Cong, Zhen Kan. <em>ICTAI  </em>, 2024.</div>
                <div class="pub-links"><a href="https://ieeexplore.ieee.org/abstract/document/10849492">Paper</a> </div>
              </div>
            </li>
          </ul>
        </section>

        <!-- <section id="talks">
          <h2>Talks</h2>
          <ul class="simple">
            <li>Workshop @ ICML 2025.</li>
            <li>Invited talk, NeurIPS 2024 Workshop.</li>
          </ul>
        </section> -->

        <section id="contact">
          <h2>Contact</h2>
          <ul class="simple">
            <li>Email: <a href="mailto:congyuren@hotmail.com">congyuren@hotmail.com</a></li>
            <li>Wechat: congyr5</li>
          </ul>
        </section>

        <footer class="meta" style="padding:12px 0 0">© <span id="year"></span> Yuren Cong</footer>
      </main>
    </div>
  </div>

  <script>
    // Theme toggle + year
    const YEAR = document.getElementById('year');
    if (YEAR) YEAR.textContent = new Date().getFullYear();

    const root = document.documentElement;
    const btn = document.getElementById('theme-toggle');
    const saved = localStorage.getItem('theme');
    if (saved) root.setAttribute('data-theme', saved);
    btn.textContent = root.getAttribute('data-theme') === 'dark' ? 'light' : 'dark';

    btn.addEventListener('click', () => {
      const next = root.getAttribute('data-theme') === 'dark' ? '' : 'dark';
      if (next) root.setAttribute('data-theme', next); else root.removeAttribute('data-theme');
      localStorage.setItem('theme', next);
      btn.textContent = next === 'dark' ? 'light' : 'dark';
    });
  </script>
</body>
</html>
