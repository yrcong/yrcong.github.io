
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Yuren Cong</title>
  <link rel="icon" type="image/x-icon" href="assets/idea.png">
</head>

<body>
    <div class="container">
        <div class="row">
            <div class="col-md-1"></div>
            <div class="col-md-10">
                <div class="row" style="margin-top: 3em;">
                    <div class="col-sm-12" style="margin-bottom: 1em;">
                    <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Yuren</span> Cong</h3>
                    </div>
                    <br>
                    <div class="col-md-10" style="">
                        
                <p>
                    I am now working as a AI research scientist at Meta, focusing on image and video generative models. Previously, I was a Ph.D. student at the <a href="https://www.tnt.uni-hannover.de/en/" target="_blank">Institute for Information Processing</a> at Leibniz University Hanover,
                    working on scene understanding and generative models.
                    I was advised by <a href="https://www.tnt.uni-hannover.de/en/staff/rosenhahn/" target="_blank">Prof. Bodo Rosenhahn</a> and <a href="https://sites.google.com/site/michaelyingyang" target="_blank">Prof. Michael Ying Yang</a>.
                </p>
                <p>
                  My research interest lies in computer vision and graphics:
                  <ul>
                    <li> Image / Video Understanding
                    <li>  Image / Video Generation
                    <li>  Multimodal Learning
                    <li>  Embodied AI
                  </ul>
                  <!-- My research interest is in 3D vision and graphics. -->
                  <!-- Particularly, I am interested in virtual human related topics, e.g., simulated character animation, human motion generation, and human mesh reconstruction.  -->
                </p>
                <p>Please feel free to contact me by email for any questions or collaboration!</p>
                <p>
                    <a href="https://scholar.google.com/citations?user=6DPcOUEAAAAJ&hl=en&oi=ao" target="_blank" style="margin-right: 5px"><i class="fa-solid fa-book"></i> Scholar</a>
                    <a href="assets/pdf/resume.pdf" target="_blank" style="margin-right: 5px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:congyuren@hotmail.com" style="margin-right: 5px"><i class="far fa-envelope-open fa-lg"></i> Mail</a>
                    <a href="https://twitter.com/CongYuren" target="_blank" style="margin-right: 5px"><i class="fab fa-twitter fa-lg"></i> Twitter</a>
                    <a href="https://github.com/yrcong" target="_blank" style="margin-right: 5px"><i class="fab fa-github fa-lg"></i> Github</a>
                    <a href="https://www.linkedin.com/in/yuren-cong-78626a193/" target="_blank" style="margin-right: 5px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                </p>
    
                    </div>
                    <div class="col-md-2" style="">
                        <img src="assets/img/profile.jpg" class="img-thumbnail" width="512px" alt="Profile picture">
                    </div>
                </div>
                <div class="row" style="margin-top: 1em;">
                    <div class="col-sm-12" style="">

<h4>Publications</h4>
<div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/leffa.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/abs/2412.08486" target="_blank">Learning Flow Fields in Attention for Controllable Person Image Generation</a>
    <br>Zijian Zhou</a>, Shikun Liu</a>, Xiao Han</a>, Haozhe Liu</a>, Kam Woh Ng</a>, Tian Xie</a>, <span style="font-weight: bold";>Yuren Cong</span>, Hang Li</a>, Mengmeng Xu</a>, Juan-Manuel Perez-Rua</a>, Aditya Patel</a>, Tao Xiang</a>, Miaojing Shi</a>, Sen He</a>,<br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </span>, 2025 <br>
    <a href="https://huggingface.co/spaces/franciszzj/Leffa" target="_blank">Huggingface</a> / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsechen2023gentron" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsechen2023gentron"><div class="card card-body"><pre><code>@article{zhou2024learning,
      title={Learning Flow Fields in Attention for Controllable Person Image Generation},
      author={Zhou, Zijian and Liu, Shikun and Han, Xiao and Liu, Haozhe and Ng, Kam Woh and Xie, Tian and Cong, Yuren and Li, Hang and Xu, Mengmeng and P{\'e}rez-R{\'u}a, Juan-Manuel and others},
      journal={arXiv preprint arXiv:2412.08486},
      year={2024}
    }
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/actig.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2301.01413.pdf" target="_blank">Attribute-Centric Compositional Text-to-Image Generation</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Martin Renqiang Min</a>, Li Erran Li</a>, Bodo Rosenhahn</a>, Michael Ying Yang</a>,<br>
    <span style="font-style: italic;">International Journal of Computer Vision (IJCV),</span> 2025 <br>
    <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023attribute" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023attribute"><div class="card card-body"><pre><code>@article{cong2023attribute,
  title={Attribute-centric compositional text-to-image generation},
  author={Cong, Yuren and Min, Martin Renqiang and Li, Li Erran and Rosenhahn, Bodo and Yang, Michael Ying},
  journal={International Journal of Computer Vision},
  year={2025}
    }
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/actig.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2301.01413.pdf" target="_blank">Indoor Scene Change Understanding (SCU): Segment, Describe, and Revert Any Change</a> <br>Mariia Khan</a>, Yue Qiu</a>,
    <span style="font-weight: bold";>Yuren Cong</span>, Bodo Rosenhahn</a>, David Suter</a>, Jumana Abu-Khalaf</a>,<br>
    <span style="font-style: italic;">International Conference on Intelligent Robots and Systems (IROS),</span> 2024 <br>
    <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023attribute" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023attribute"><div class="card card-body"><pre><code>@inproceedings{khan2024indoor,
  title={Indoor Scene Change Understanding (SCU): Segment, Describe, and Revert Any Change},
  author={Khan, Mariia and Qiu, Yue and Cong, Yuren and Rosenhahn, Bodo and Suter, David and Abu-Khalaf, Jumana},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9777--9783},
  year={2024},
  organization={IEEE}
    }
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/gentron.gif" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2312.04557.pdf" target="_blank">GenTron: Delving Deep into Diffusion Transformers for Image and Video Generation</a>
    <br>Shoufa Chen</a>, Mengmeng Xu</a>, Jiawei Ren</a>, <span style="font-weight: bold";>Yuren Cong</span>, Sen He</a>, Yanping Xie</a>, Animesh Sinha</a>, Ping Luo</a>, Tao Xiang</a>, Juan-Manuel Perez-Rua</a>,<br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </span>, 2024 <br>
    <a href="https://www.shoufachen.com/gentron_website/" target="_blank">Project Page</a> / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsechen2023gentron" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsechen2023gentron"><div class="card card-body"><pre><code>@misc{chen2023gentron,
      title={GenTron: Delving Deep into Diffusion Transformers for Image and Video Generation},
      author={Shoufa Chen and Mengmeng Xu and Jiawei Ren and Yuren Cong and Sen He and Yanping Xie and Animesh Sinha and Ping Luo and Tao Xiang and Juan-Manuel Perez-Rua},
      year={2023},
      eprint={2312.04557},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
    }
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/flatten.gif" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2310.05922.pdf" target="_blank">FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing</a>
    <br><span style="font-weight: bold";>Yuren Cong</span>, Mengmeng Xu</a>, Christian Simon</a>, Shoufa Chen</a>, Jiawei Ren</a>, Yanping Xie</a>, Juan-Manuel Perez-Rua</a>, Bodo Rosenhahn</a>, Tao Xiang</a>, Sen He</a>,<br>
    <span style="font-style: italic;">In International Conference on Learning Representations (ICLR)</span>, 2024 <br>
    <a href="https://flatten-video-editing.github.io/" target="_blank">Project Page</a> / <a href="https://github.com/yrcong/FLATTEN_video_editing" target="_blank">Code</a> / <a href="https://flatten-video-editing.github.io/static/videos/flatten_video_editing.mp4" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023flatten" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023flatten"><div class="card card-body"><pre><code>@article{cong2023flatten,
  title={FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing},
  author={Cong, Yuren and Xu, Mengmeng and Simon, Christian and Chen, Shoufa and Ren, Jiawei and Xie, Yanping and Perez-Rua, Juan-Manuel and Rosenhahn, Bodo and Xiang, Tao and He, Sen},
  journal={arXiv preprint arXiv:2310.05922},
  year={2023}
}
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/span.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2304.00590.pdf" target="_blank">Learning Similarity between Scene Graphs and Images with Transformers</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Wentong Liao</a>, Jiawei Ren</a>, Bodo Rosenhahn</a>, Michael Ying Yang</a>,<br>
    <span style="font-style: italic;">arXiv.org (under review),</span> 2023 <br>
    <a href="https://yrcong.github.io/gicon/" target="_blank">Project Page</a> / <a href="https://github.com/yrcong/Learning_Similarity_between_Graphs_Images" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023learning" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023learning"><div class="card card-body"><pre><code>@article{cong2023learning,
  title={Learning Similarity between Scene Graphs and Images with Transformers},
  author={Cong, Yuren and Liao, Wentong and Rosenhahn, Bodo and Yang, Michael Ying},
  journal={arXiv preprint arXiv:2304.00590},
  year={2023}
}
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/ssgvs.gif" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://openaccess.thecvf.com/content/CVPR2023W/MULA/papers/Cong_SSGVS_Semantic_Scene_Graph-to-Video_Synthesis_CVPRW_2023_paper.pdf" target="_blank">SSGVS: Semantic Scene Graph-to-Video Synthesis</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Jinhui Yi</a>, Bodo Rosenhahn, Michael Ying Yang</a>, </a><br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</span>, 2023 <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2023W/MULA/supplemental/Cong_SSGVS_Semantic_Scene_CVPRW_2023_supplemental.pdf" target="_blank">Supplemental</a> / <a href="https://github.com/yrcong/ssgvs" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseCong_2023_CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseCong_2023_CVPR"><div class="card card-body"><pre><code>@InProceedings{Cong_2023_CVPR,
    author    = {Cong, Yuren and Yi, Jinhui and Rosenhahn, Bodo and Yang, Michael Ying},
    title     = {SSGVS: Semantic Scene Graph-to-Video Synthesis},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2023},
    pages     = {2555-2565}
}
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/reltr.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://ieeexplore.ieee.org/abstract/document/10105507" target="_blank">Reltr: Relation Transformer for Scene Graph Generation</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Michael Ying Yang</a>, Bodo Rosenhahn, </a><br>
    <span style="font-style: italic;">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</span>, 2023 <br>
     <a href="https://github.com/yrcong/RelTR" target="_blank">Code</a> / <a href="https://colab.research.google.com/drive/1-U642OoCyb8OSM8nx9lme49dmWa_aUcU?usp=sharing" target="_blank">Colab</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2023reltr" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2023reltr"><div class="card card-body"><pre><code>@article{cong2023reltr,
  title={Reltr: Relation transformer for scene graph generation},
  author={Cong, Yuren and Yang, Michael Ying and Rosenhahn, Bodo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/sttran.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cong_Spatial-Temporal_Transformer_for_Dynamic_Scene_Graph_Generation_ICCV_2021_paper.pdf" target="_blank">Spatial-temporal Transformer for Dynamic Scene Graph Generation</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Wentong Liao</a>, Hanno Ackermann</a>, Bodo Rosenhahn</a>, Michael Ying Yang</a>,<br>
    <span style="font-style: italic;">Proc. of the IEEE/CVF International Conference on Computer Vision (ICCV)</span>, 2021 <br>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Cong_Spatial-Temporal_Transformer_for_ICCV_2021_supplemental.pdf" target="_blank">Supplemental</a> / <a href="https://github.com/yrcong/STTran" target="_blank">Code</a> / <a href="https://www.youtube.com/watch?v=6D3ExjQpbjQ" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseCong_2021_ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseCong_2021_ICCV"><div class="card card-body"><pre><code>@InProceedings{Cong_2021_ICCV,
    author    = {Cong, Yuren and Liao, Wentong and Ackermann, Hanno and Rosenhahn, Bodo and Yang, Michael Ying},
    title     = {Spatial-Temporal Transformer for Dynamic Scene Graph Generation},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {16372-16382}
}
</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/nodis.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">
    <a href="https://arxiv.org/pdf/2001.04735.pdf" target="_blank">NODIS: Neural Ordinary Differential Scene Understanding</a> <br>
    <span style="font-weight: bold";>Yuren Cong</span>, Hanno Ackermann</a>, Wentong Liao</a>, Michael Ying Yang</a>, Bodo Rosenhahn</a>,<br>
    <span style="font-style: italic;">Proc. of the European Conference on Computer Vision (ECCV) </span>, 2020 <br>
    <a href="https://github.com/yrcong/nodis" target="_blank">Code</a> / <a href="https://www.youtube.com/watch?v=4VLnOpeIzjs" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsecong2020nodis" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsecong2020nodis"><div class="card card-body"><pre><code>@InProceedings{cong2020nodis,
  title={Nodis: Neural ordinary differential scene understanding},
  author={Cong, Yuren and Ackermann, Hanno and Liao, Wentong and Yang, Michael Ying and Rosenhahn, Bodo},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XX 16},
  pages={636--653},
  year={2020},
  organization={Springer}
}
<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
  integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
  integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
  crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
  integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
  crossorigin="anonymous"></script>
</body>
</html>
    
